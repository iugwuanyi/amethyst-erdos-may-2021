{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689ac673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the necessary Packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257643c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the saved data frames that include file name and extracted text from the PDFs\n",
    "#For python>=3.8 pd.read_pickle does the work. Otherwise, it is necessary to use pickle5. \n",
    "\n",
    "try:\n",
    "    Files_tesseract=pd.read_pickle('../pytesseract_results.dat')\n",
    "except:\n",
    "    #!pip3 install pickle5\n",
    "    import pickle5 as pickle\n",
    "    with open('../pytesseract_results.dat','rb') as fh:\n",
    "        Files_tesseract = pickle.load(fh,encoding='unicode')\n",
    "\n",
    "try:\n",
    "    Files_pdfminer=pd.read_pickle('../pdfminer_ables.dat')\n",
    "except:\n",
    "    #!pip3 install pickle5\n",
    "    import pickle5 as pickle\n",
    "    with open('../pdfminer_ables.dat','rb') as fh:\n",
    "        Files_pdfminer = pickle.load(fh,encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fcd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a common column for the extracted text in both data frames.\n",
    "Files_tesseract['extracted_text']=Files_tesseract['reparse']\n",
    "Files_pdfminer['extracted_text']=Files_pdfminer['de_headed']\n",
    "\n",
    "#Combine the data frames, substituting the rows on Files_pdfminer by those included in Files_tesseract.\n",
    "All_Texts_DF=Files_tesseract.combine_first(Files_pdfminer)\n",
    "\n",
    "#Keep just the useful columns\n",
    "All_Texts_DF=All_Texts_DF[['filename','extracted_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba9d972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>extracted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990_april_24_587321468019152780_conformed-cop...</td>\n",
       "      <td>CONFORMED COPY\\n\\nLOAN NUMBER 3186 IVC\\n\\nLoan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990_april_24_668811468165272290_conformed-cop...</td>\n",
       "      <td>CONFORMED COPY\\n\\n                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990_april_25_904191468298750561_conformed-cop...</td>\n",
       "      <td>CONFORMED COPY\\n\\n                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1990_april_30_410811468040573756_conformed-cop...</td>\n",
       "      <td>CONFORMED COPY\\n\\n                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1990_april_30_725911468042268845_conformed-cop...</td>\n",
       "      <td>CONFORMED COPY\\n\\n                            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>2019_september_13_300871570120923592_official-...</td>\n",
       "      <td>OFFICIAL\\nDOCUMENTS\\n\\n=＝ ニニ ニニニ ニニ ニニ にニ ニニニ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>2019_september_13_710891569417913880_official-...</td>\n",
       "      <td>Public Disclosure Authorized\\n\\nPublic Disclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>2019_september_23_867961572361092133_official-...</td>\n",
       "      <td>Public Disclosure Authorized\\n\\nPublic Disclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3203</th>\n",
       "      <td>2019_september_25_810411569965213165_official-...</td>\n",
       "      <td>Public Disclosure Authorized\\n\\nPublic Disclos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>2019_september_6_898111568752266404_official-d...</td>\n",
       "      <td>Public Disclosure Authorized\\n\\nPublic Disclos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3205 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename  \\\n",
       "0     1990_april_24_587321468019152780_conformed-cop...   \n",
       "1     1990_april_24_668811468165272290_conformed-cop...   \n",
       "2     1990_april_25_904191468298750561_conformed-cop...   \n",
       "3     1990_april_30_410811468040573756_conformed-cop...   \n",
       "4     1990_april_30_725911468042268845_conformed-cop...   \n",
       "...                                                 ...   \n",
       "3200  2019_september_13_300871570120923592_official-...   \n",
       "3201  2019_september_13_710891569417913880_official-...   \n",
       "3202  2019_september_23_867961572361092133_official-...   \n",
       "3203  2019_september_25_810411569965213165_official-...   \n",
       "3204  2019_september_6_898111568752266404_official-d...   \n",
       "\n",
       "                                         extracted_text  \n",
       "0     CONFORMED COPY\\n\\nLOAN NUMBER 3186 IVC\\n\\nLoan...  \n",
       "1     CONFORMED COPY\\n\\n                            ...  \n",
       "2     CONFORMED COPY\\n\\n                            ...  \n",
       "3     CONFORMED COPY\\n\\n                            ...  \n",
       "4     CONFORMED COPY\\n\\n                            ...  \n",
       "...                                                 ...  \n",
       "3200  OFFICIAL\\nDOCUMENTS\\n\\n=＝ ニニ ニニニ ニニ ニニ にニ ニニニ ...  \n",
       "3201  Public Disclosure Authorized\\n\\nPublic Disclos...  \n",
       "3202  Public Disclosure Authorized\\n\\nPublic Disclos...  \n",
       "3203  Public Disclosure Authorized\\n\\nPublic Disclos...  \n",
       "3204  Public Disclosure Authorized\\n\\nPublic Disclos...  \n",
       "\n",
       "[3205 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Texts_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d90399d",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Below we print the extracted text from a random PDF. Note that to extract sensible information it makes sense to parse the document line by line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32466a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFFICIAL\n",
      "DOCUMENTS,\n",
      "\n",
      "LOAN  NUMBER  8342-AM\n",
      "\n",
      "Loan Agreement\n",
      "\n",
      "(Education  Improvement  Project)\n",
      "\n",
      "REPUBLIC  OF  ARMENIA\n",
      "\n",
      "between\n",
      "\n",
      "and\n",
      "\n",
      "INTERNATIONAL  BANK  FOR RECONSTRUCTION\n",
      "AND  DEVELOPMENT\n",
      "\n",
      "Dated \n",
      "\n",
      "3 \n",
      "\n",
      ",2014\n",
      "\n",
      "\f",
      "LOAN  NUMBER  8342-AM\n",
      "\n",
      "LOAN  AGREEMENT\n",
      "\n",
      "Agreement  dated \n",
      "\n",
      ",  2014,  between  the REPUBLIC\n",
      "FOR\n",
      "OF  ARMENIA \n",
      "RECONSTRUCTION  AND  DEVELOPMENT  (\"Bank\").  The  Borrower  and  the  Bank\n",
      "hereby  agree  as follows:\n",
      "\n",
      "INTERNATIONAL \n",
      "\n",
      "(\"Borrower\") \n",
      "\n",
      "BANK \n",
      "\n",
      "and \n",
      "\n",
      "the \n",
      "\n",
      "ARTICLE  I - GENERAL  CONDITIONS;  DEFINITIONS\n",
      "\n",
      "1.01. \n",
      "\n",
      "The  General  Conditions  (as  defined \n",
      "constitute an  integral  part of this Agreement.\n",
      "\n",
      "in  the  Appendix  to  this  Agreement)\n",
      "\n",
      "1.02.  Unless  the  context  requires  otherwise, \n",
      "\n",
      "this\n",
      "Agreement  have  the  meanings  ascribed  to  them  in  the  General  Conditions  or  in\n",
      "the Appendix  to this Agreement.\n",
      "\n",
      "the  capitalized \n",
      "\n",
      "terms  used  in \n",
      "\n",
      "ARTICLE  II - LOAN\n",
      "\n",
      "2.01. \n",
      "\n",
      "The  Bank agrees  to  lend to the Borrower,  on the terms  and conditions  set  forth or\n",
      "referred\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_text=random.choice(All_Texts_DF.extracted_text)\n",
    "print(random_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85fd021",
   "metadata": {},
   "source": [
    "To preprocess the text we do the following:\n",
    "    - Replace non alpha numeric values (except for periods, parenthesis and possible currency characters.\n",
    "    - Treat double newline and period, colon or semicolon followed by a newline as a new paragraph. \n",
    "    - Treat simple newlines as part of the same paragraph. \n",
    "    - Eliminate extra spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1b03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function formats the text to be able to differentiate paragraphs and lines. \n",
    "#Declare currency characters, to identify amount of loan. \n",
    "currency_characters=u'$¢£¤¥֏؋৲৳৻૱௹฿៛\\u20a0-\\u20bd\\ua838\\ufdfc\\ufe69\\uff04\\uffe0\\uffe1\\uffe5\\uffe6'\n",
    "\n",
    "def separate_lines(text,currency_characters=currency_characters,simple_line=' ',separator='\\n'):  \n",
    "    #Treat dot, colon and semicolon followed by newline as a new paragraph. \n",
    "    text=re.sub('[:;.](\\n)','\\n\\n',text)\n",
    "    \n",
    "    #Eliminate lines of only space characters\n",
    "    text=re.sub('\\n\\s+\\n','\\n\\n',text)\n",
    "    \n",
    "    #Replace single newlines as an space (since we are still in the same paragraph)\n",
    "    text=re.sub('\\n(?!\\n)',simple_line,text)\n",
    "    \n",
    "    #Replace multiple newlines with a single one. \n",
    "    text=re.sub('\\n+[\\n\\s]*','\\n',text)\n",
    "    \n",
    "    #Erase non alphanumeric, dots, parenthesis or currency characters\n",
    "    re_string='[^0-9a-zA-Z\\s.\\(\\)'+currency_characters+']+'\n",
    "    text=re.sub(re_string, '',text)\n",
    "    text=text.replace('\"','')\n",
    "    text=re.sub('( ){2,}',' ',text)\n",
    "    \n",
    "    #Separate into lines/paragraphs\n",
    "    lines=re.split(separator,text)\n",
    "    lines=[l.strip() for l in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9120c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to work with parenthesis\n",
    "#Taken from https://stackoverflow.com/a/38212660/3254178\n",
    "def extract_parenthesis(string):\n",
    "    flag = 0\n",
    "    result, accum = [], []\n",
    "    for c in string:\n",
    "        if c == ')':\n",
    "            flag -= 1\n",
    "        if flag:\n",
    "            accum.append(c)\n",
    "        if c == '(':\n",
    "            flag += 1\n",
    "        if not flag and accum:\n",
    "            result.append(''.join(accum))\n",
    "            accum = []\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe4e92",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "## Project Name\n",
    "We scan the document line by line until we find the first line with the words \"loan\" or \"agreement\" on them. \n",
    "We then interpret the first line with text in between parenthesis as the project name. \n",
    "We only look at the first 35 lines, if we dont find a line following this pattern, we return none. \n",
    "We also make sure the Project Name doesn't include any of the unwanted_words, that sometimes appear in a similar format, but are not the name. We also discard the possible name if it is too short (less than 12 characters). \n",
    "\n",
    "## Project Description\n",
    "Many documents include a section describing the project. We look for the line with the words \"project\" and \"description\", followed by a paragrah with the word \"objective(s)\". We return the first 3 lines (paragraphs) after this point.  \n",
    "\n",
    "## Loan Amount and Currency\n",
    "We find the paragraph with the key words \"bank\", \"agrees\", \"borrower\" and \"amount\". Then we look for the loan amount in that line or the next with a regular expressioon, it usually looks like $ 2000000. \n",
    "\n",
    "## Country Code\n",
    "Many documents include in the first page a Loan number that includes a country code of 2 or 3 letters. \n",
    "We find the first line following the pattern \"number AAA\" and return that code. \n",
    "As we describe elsewhere, these codes are not unique and dont follow any ISO standard, so it isn't enough to accurately identify the country. \n",
    "\n",
    "## Possible Country Name\n",
    "Many documents include the name of the country in the first page. We look for the first line with the word \"between\" and the first line with the word \"article\", and consider just the lines close to them. We then extract all small sentences of all uppercase letters as they may be the country name. We clean them by eliminating stop words and words that could confuse our fuzzy matching to identify countries, and return a list of all these possible sentences. \n",
    "\n",
    "##Address\n",
    "We find the word \"addresses\" in the document, and then extract everything in the address for the borrower. We identified 4 possible patterns for this. \n",
    "\n",
    "## Date\n",
    "We extract the date from the file name. All file names follow the pattern YYY--MM--DD--numbers_and_text. It returns a datetime object with the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031d0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_words=['borrower','lender','rate','guarantee','agreement','guarantor','amendment']\n",
    "max_line_first_page=35 #This was decided after trying some values\n",
    "\n",
    "#Returns: Project Name, line number where it was found.\n",
    "def get_project_name(lines,line_num,unwanted_words=unwanted_words,max_line_first_page=max_line_first_page):\n",
    "    found_start=False\n",
    "    line_max=min([max_line_first_page,len(lines)]) \n",
    "    while line_num <line_max:\n",
    "        l=lines[line_num]\n",
    "        if found_start:\n",
    "            #Look for a line of text in between two parenthesis\n",
    "            m=re.search('\\(\\s*([a-z]+[(),:;a-z\\s\\d]+)(project)?\\s*\\)',l.lower())\n",
    "            if m!=None and len(m.group(1))>12:\n",
    "                #Sometimes Parenthesis can be messy, so we extract the text on the outermost parenthesis\n",
    "                if len(re.findall('\\(',m.group(0)))>1:\n",
    "                    name=extract_parenthesis(m.group(0))\n",
    "                    if len(name)>0: #This must have at least one string if the parenthesis were balanced\n",
    "                        name=name[0]\n",
    "                    else: #if the parenthesis were not balanced, return everything before the second (\n",
    "                        m=re.search('(.*)\\(',m.group(1))\n",
    "                        name=m.group(1)\n",
    "                else:\n",
    "                    name=m.group(1)\n",
    "                if len(name)>12 and not(any(elem in name.split(' ') for elem in unwanted_words)) and not ('general conditions' in name):\n",
    "                    return name,line_num\n",
    "        else:\n",
    "            words=l.lower().split(' ')\n",
    "            if ('loan' in words) or ('agreement' in words):\n",
    "                #Once we found the sentence with loan or agreement in it, we start looking for the Project Name\n",
    "                found_start=True\n",
    "                line_num-=1\n",
    "        line_num+=1\n",
    "    #If couldnt find a Project Name following the format, returns None\n",
    "    return None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50a68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns: Project Description, line number where it was found.\n",
    "def get_project_description(lines, line_num):\n",
    "    line_max=len(lines)\n",
    "    while line_num <line_max-2:\n",
    "        l=lines[line_num]\n",
    "        words=l.split(' ')\n",
    "        if all([w in words for w in ['Project','Description']]):\n",
    "            description=' '.join([lines[line_num], lines[line_num+1],lines[line_num+2]])\n",
    "            if 'objective' in description.lower():\n",
    "                return description, line_num\n",
    "        line_num+=1\n",
    "    return None,line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "388bc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns loan_amount, currency, line where it was found\n",
    "def get_loan_amount_currency(lines, line_num0):\n",
    "    #Extract dollar amount\n",
    "    #Extract the values using Regular Expressions\n",
    "    currency_characters=u\"[$¢£¤¥֏؋৲৳৻૱௹฿៛\\u20a0-\\u20bd\\ua838\\ufdfc\\ufe69\\uff04\\uffe0\\uffe1\\uffe5\\uffe6]|\"\n",
    "    currency_abbs=u'[\\s\\(]\\s?[a-z]{1,3}'\n",
    "    regexp_amount='(amount|value).*?('+currency_characters+currency_abbs+')([ \\d]{6,})'\n",
    "\n",
    "    line_num=line_num0\n",
    "    while line_num<len(lines)-3:\n",
    "        #Combine with the following three lines\n",
    "        combined_lines=' '.join([lines[line_num],lines[line_num+1],lines[line_num+2],lines[line_num+3]]) \n",
    "        combined_lines=combined_lines.lower()\n",
    "        #Find the line where it talks about the loan amount\n",
    "        if all(elem in combined_lines for elem in ['bank','agrees','borrower','amount']):  \n",
    "            #Search the regular expression\n",
    "            value=re.search(regexp_amount,combined_lines)\n",
    "            #Eliminate commas\n",
    "            combined_lines=combined_lines.replace(',','')\n",
    "            if value!=None:\n",
    "                amount=value.group(3)\n",
    "                amount=amount.replace(' ','')\n",
    "                amount=int(amount)\n",
    "                currency=value.group(2)\n",
    "                currency=currency.replace('(','')\n",
    "                currency=currency.strip()\n",
    "                #Make double sure that the amount makes sense. \n",
    "                if amount>100000:\n",
    "                    return amount,currency,line_num\n",
    "        line_num+=1\n",
    "    #If we couldnt find an amount, return None\n",
    "    return None,None,line_num0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b265a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_code(lines,max_line_first_page=max_line_first_page):\n",
    "    max_line=min(max_line_first_page,len(lines))\n",
    "    line_num=0\n",
    "    while line_num<max_line:\n",
    "        l=lines[line_num].lower()\n",
    "        m=re.search('numbers? .*?([a-z]{2,3})[ ]?$',l)\n",
    "        if m!=None:\n",
    "            code=m.group(1)\n",
    "            code=code.upper()\n",
    "            return code,line_num\n",
    "        line_num+=1\n",
    "    return None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e597724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#extra common stop_words\n",
    "stop_words=stop_words.union(['bank', 'state','agreement', 'loan', 'development','number', 'international', 'whereas', 'therefore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8aea52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stop_words=stop_words):\n",
    "    words=text.lower().split(' ')\n",
    "    words=[w for w in words if not w in stop_words]\n",
    "    text=' '.join(words).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d274c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_country_names(lines, stop_words=stop_words):\n",
    "    for ind, line in enumerate(lines):\n",
    "        start=0\n",
    "        if start==0 and 'between' in line.lower():\n",
    "            start=max(ind-2,0)\n",
    "        if 'article' in line.lower():\n",
    "            #Combine all lines between start and the line before the word \"article\"\n",
    "            text='\\n'.join(lines[start:ind-1])\n",
    "            #Find all short sentences of all caps, of 4 or more letters. \n",
    "            possible_countries=re.findall('[A-Z]{4,}[A-Z ]+',text)\n",
    "            \n",
    "            #Clean all possible countries\n",
    "            possible_countries=[clean(possible,stop_words) for possible in possible_countries]\n",
    "            possible_countries=[possible for possible in possible_countries if not possible=='' and len(possible)>3]  \n",
    "            return '\\n'.join(possible_countries)\n",
    "        #Otherwise return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6dc8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacing_and_lower(docu):\n",
    "    docu = docu.replace('  ',' ')\n",
    "    docu = docu.replace('   ',' ')\n",
    "    docu = docu.lower()\n",
    "    return docu\n",
    "\n",
    "def read_address(docu, pin0= 'addresses', pin1 = 'start', pin2 = 'end'):\n",
    "    start = docu.find(pin0)\n",
    "    borrower = docu[start:].find(pin1)\n",
    "    colon = docu[start+borrower:].find(':')\n",
    "    bank = docu[start+borrower+colon:].find(pin2)\n",
    "    add = docu[start+borrower+colon+1:start+borrower+colon+bank]\n",
    "    if 'in witness' in add:\n",
    "        end2 = docu[start+borrower+colon+1:].find('in witness')\n",
    "        add = add[:end2]\n",
    "    return add\n",
    "\n",
    "def get_address(text):\n",
    "    text=spacing_and_lower(text)\n",
    "    #We try 4 different patterns to get the address\n",
    "    pairs_of_pins=[('for the borrower','for the bank'),('for the borrower','international bank'),\n",
    "                   ('address is','the bank'),('the borrower','the world bak')]\n",
    "    \n",
    "    for pin1,pin2 in pairs_of_pins:\n",
    "        address = read_address(text, pin0 = 'addresses', pin1=pin1, pin2=pin2)\n",
    "        if 8<len(address)<500:\n",
    "            return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f8121f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following Function extracts the date from the file_name and returns it as a datetime.datetime object\n",
    "def get_date_file_name(file_name):\n",
    "    file_split=file_name.split('--')\n",
    "    date=datetime.datetime.strptime(' '.join(file_split[0].split('_')[0:3]),'%Y %B %d')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710b2fe",
   "metadata": {},
   "source": [
    "Finally we create empty columns for all the attributes and we extract them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e75c5646",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Texts_DF['Project_name']=None\n",
    "All_Texts_DF['Project_desc']=None\n",
    "All_Texts_DF['Date']=None\n",
    "All_Texts_DF['Currency']=''\n",
    "All_Texts_DF['Amount_loan']=None\n",
    "All_Texts_DF['Country_code_pdf']=None\n",
    "All_Texts_DF['Possible_country_name']=None\n",
    "All_Texts_DF['Address']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16790d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in All_Texts_DF.index:\n",
    "    text=All_Texts_DF['extracted_text'][i]\n",
    "    file_name=All_Texts_DF['filename'][i]\n",
    "    \n",
    "    All_Texts_DF['Date'][i]=get_date_file_name(file_name)\n",
    "    \n",
    "    lines=separate_lines(text)\n",
    "    All_Texts_DF['Country_code_pdf'][i],line_num=get_country_code(lines)\n",
    "    All_Texts_DF['Project_name'][i],line_num=get_project_name(lines,line_num)\n",
    "    \n",
    "    amount,currency, line_num=get_loan_amount_currency(lines,line_num)\n",
    "    All_Texts_DF['Currency'][i]=currency\n",
    "    All_Texts_DF['Amount_loan'][i]=amount\n",
    "    \n",
    "    description, _=get_project_description(lines,line_num)\n",
    "    All_Texts_DF['Project_desc'][i]=description\n",
    "    \n",
    "    All_Texts_DF['Possible_country_name'][i]=get_possible_country_names(lines)\n",
    "    \n",
    "    All_Texts_DF['Address'][i]=get_address(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf542046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Name  78\n",
      "No Currency  228\n",
      "No Amount  228\n",
      "No Country Code  111\n",
      "No Project Description  839\n",
      "No Address  154\n"
     ]
    }
   ],
   "source": [
    "#How many NONEs?\n",
    "print('No Name ',All_Texts_DF.Project_name.isnull().sum())\n",
    "print('No Currency ',All_Texts_DF.Currency.isnull().sum())\n",
    "print('No Amount ',All_Texts_DF.Amount_loan.isnull().sum())\n",
    "print('No Country Code ',All_Texts_DF.Country_code_pdf.isnull().sum())\n",
    "print('No Project Description ',All_Texts_DF.Project_desc.isnull().sum())\n",
    "print('No Address ',All_Texts_DF.Address.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3114e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We couldnt extract all the info for:  456  PDFs.\n"
     ]
    }
   ],
   "source": [
    "#Dont Want to count empty description as a NONE PDF (maybe the title has enough information)\n",
    "All_Texts_DF.loc[All_Texts_DF.Project_desc.isnull(),'Project_desc']=''\n",
    "print('We couldnt extract all the info for: ',All_Texts_DF.shape[0]-All_Texts_DF.dropna().shape[0],' PDFs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85f3a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "DF_to_export=All_Texts_DF.drop('extracted_text',axis=1)\n",
    "DF_to_export.to_csv('Extracted_Attributes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bffd36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
