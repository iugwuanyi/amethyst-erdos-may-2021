{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the necessary Packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pickle5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c99e5b654e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mFiles_tesseract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../pytesseract_results.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../pytesseract_results.dat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c99e5b654e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#!pip3 install pickle5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpickle5\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../pytesseract_results.dat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mFiles_tesseract\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unicode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pickle5'"
     ]
    }
   ],
   "source": [
    "#Read the saved data frames that include file name and extracted text from the PDFs\n",
    "#For python>=3.8 pd.read_pickle does the work. Otherwise, it is necessary to use pickle5. \n",
    "\n",
    "try:\n",
    "    Files_tesseract=pd.read_pickle('../../pytesseract_results.dat')\n",
    "except:\n",
    "    #!pip3 install pickle5\n",
    "    import pickle5 as pickle\n",
    "    with open('../../pytesseract_results.dat','rb') as fh:\n",
    "        Files_tesseract = pickle.load(fh,encoding='unicode')\n",
    "\n",
    "try:\n",
    "    Files_pdfminer=pd.read_pickle('../../pdfminer_ables.dat')\n",
    "except:\n",
    "    #!pip3 install pickle5\n",
    "    import pickle5 as pickle\n",
    "    with open('../../pdfminer_ables.dat','rb') as fh:\n",
    "        Files_pdfminer = pickle.load(fh,encoding='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Files_tesseract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c9f566d16c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create a common column for the extracted text in both data frames.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mFiles_tesseract\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extracted_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFiles_tesseract\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reparse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mFiles_pdfminer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'extracted_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFiles_pdfminer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'de_headed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Combine the data frames, substituting the rows on Files_pdfminer by those included in Files_tesseract.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Files_tesseract' is not defined"
     ]
    }
   ],
   "source": [
    "#Create a common column for the extracted text in both data frames.\n",
    "Files_tesseract['extracted_text']=Files_tesseract['reparse']\n",
    "Files_pdfminer['extracted_text']=Files_pdfminer['de_headed']\n",
    "\n",
    "#Combine the data frames, substituting the rows on Files_pdfminer by those included in Files_tesseract.\n",
    "All_Texts_DF=Files_tesseract.combine_first(Files_pdfminer)\n",
    "\n",
    "#Keep just the useful columns\n",
    "All_Texts_DF=All_Texts_DF[['filename','extracted_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'All_Texts_DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b01238b6e459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAll_Texts_DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'All_Texts_DF' is not defined"
     ]
    }
   ],
   "source": [
    "All_Texts_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Below we print the extracted text from a random PDF. Note that to extract sensible information it makes sense to parse the document line by line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAN  NUMBER  3955-CO  (Floating  Rate)\n",
      "\n",
      "Loan  Agreement\n",
      "\n",
      "(Power Market  Development  Project)\n",
      "\n",
      "INTERNATIONAL  BANK  FOR RECONSTRUCTION\n",
      "AND  DEVELOPMENT\n",
      "\n",
      "between\n",
      "\n",
      "and\n",
      "\n",
      "INTERCONEXION ELECTRICA S.A.  \"E.S.P.\"\n",
      "\n",
      "Dated \n",
      "\n",
      ", 1996\n",
      "\n",
      "\f",
      "LOAN  NUMBER  3955-CO\n",
      "\n",
      "LOAN  AGREEMENT\n",
      "\n",
      "AGREEMENT,  dated  Po4t \n",
      "\n",
      "U \n",
      "\n",
      "BANK  FOR  RECONSTRUCTION  AND  DEVELOPMENT \n",
      "INTERCONEXION  ELECTRICA  S.A.\"E.S.P.\"  (the  Borrower).\n",
      "\n",
      ",  1996  between  INTERNATIONAL\n",
      "and\n",
      "\n",
      "(the  Bank) \n",
      "\n",
      "WHEREAS  (A)  REPUBLIC OF COLOMBIA (the Guarantor)  and the Borrower,\n",
      "having been satisfied as to the feasibility  and priority  of the Project  described in  Schedule\n",
      "2 to this Agreement,  have requested  the  Bank to  assist in the  financing  of the Project;\n",
      "\n",
      "(B) \n",
      "\n",
      "by  an  agreement  (the  Guarantee  Agreement)  of  even  date  herewith\n",
      "between  the  Guarantor  and  the  Bank,  the  Guarantor  has  agreed  to  guarantee  the\n",
      "obligations of the Borrower in respect of the Loan and to undertake  such other obligations\n",
      "as  set forth  in the  Guar\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_text=random.choice(All_Texts_DF.extracted_text)\n",
    "print(random_text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess the text we do the following:\n",
    "    - Replace non alpha numeric values (except for periods, parenthesis and possible currency characters.\n",
    "    - Treat double newline and period, colon or semicolon followed by a newline as a new paragraph. \n",
    "    - Treat simple newlines as part of the same paragraph. \n",
    "    - Eliminate extra spaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following function formats the text to be able to differentiate paragraphs and lines. \n",
    "#Declare currency characters, to identify amount of loan. \n",
    "currency_characters=u'$¢£¤¥֏؋৲৳৻૱௹฿៛\\u20a0-\\u20bd\\ua838\\ufdfc\\ufe69\\uff04\\uffe0\\uffe1\\uffe5\\uffe6'\n",
    "\n",
    "def separate_lines(text,currency_characters=currency_characters,simple_line=' ',separator='\\n'):  \n",
    "    #Treat dot, colon and semicolon followed by newline as a new paragraph. \n",
    "    text=re.sub('[:;.](\\n)','\\n\\n',text)\n",
    "    \n",
    "    #Eliminate lines of only space characters\n",
    "    text=re.sub('\\n\\s+\\n','\\n\\n',text)\n",
    "    \n",
    "    #Replace single newlines as an space (since we are still in the same paragraph)\n",
    "    text=re.sub('\\n(?!\\n)',simple_line,text)\n",
    "    \n",
    "    #Replace multiple newlines with a single one. \n",
    "    text=re.sub('\\n+[\\n\\s]*','\\n',text)\n",
    "    \n",
    "    #Erase non alphanumeric, dots, parenthesis or currency characters\n",
    "    re_string='[^0-9a-zA-Z\\s.\\(\\)'+currency_characters+']+'\n",
    "    text=re.sub(re_string, '',text)\n",
    "    text=text.replace('\"','')\n",
    "    text=re.sub('( ){2,}',' ',text)\n",
    "    \n",
    "    #Separate into lines/paragraphs\n",
    "    lines=re.split(separator,text)\n",
    "    lines=[l.strip() for l in lines]\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to work with parenthesis\n",
    "#Taken from https://stackoverflow.com/a/38212660/3254178\n",
    "def extract_parenthesis(string):\n",
    "    flag = 0\n",
    "    result, accum = [], []\n",
    "    for c in string:\n",
    "        if c == ')':\n",
    "            flag -= 1\n",
    "        if flag:\n",
    "            accum.append(c)\n",
    "        if c == '(':\n",
    "            flag += 1\n",
    "        if not flag and accum:\n",
    "            result.append(''.join(accum))\n",
    "            accum = []\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "## Project Name\n",
    "We scan the document line by line until we find the first line with the words \"loan\" or \"agreement\" on them. \n",
    "We then interpret the first line with text in between parenthesis as the project name. \n",
    "We only look at the first 35 lines, if we dont find a line following this pattern, we return none. \n",
    "We also make sure the Project Name doesn't include any of the unwanted_words, that sometimes appear in a similar format, but are not the name. We also discard the possible name if it is too short (less than 12 characters). \n",
    "\n",
    "## Project Description\n",
    "Many documents include a section describing the project. We look for the line with the words \"project\" and \"description\", followed by a paragrah with the word \"objective(s)\". We return the first 3 lines (paragraphs) after this point.  \n",
    "\n",
    "## Loan Amount and Currency\n",
    "We find the paragraph with the key words \"bank\", \"agrees\", \"borrower\" and \"amount\". Then we look for the loan amount in that line or the next with a regular expressioon, it usually looks like $ 2000000. \n",
    "\n",
    "## Country Code\n",
    "Many documents include in the first page a Loan number that includes a country code of 2 or 3 letters. \n",
    "We find the first line following the pattern \"number AAA\" and return that code. \n",
    "As we describe elsewhere, these codes are not unique and dont follow any ISO standard, so it isn't enough to accurately identify the country. \n",
    "\n",
    "## Possible Country Name\n",
    "Many documents include the name of the country in the first page. We look for the first line with the word \"between\" and the first line with the word \"article\", and consider just the lines close to them. We then extract all small sentences of all uppercase letters as they may be the country name. We clean them by eliminating stop words and words that could confuse our fuzzy matching to identify countries, and return a list of all these possible sentences. \n",
    "\n",
    "##Address\n",
    "We find the word \"addresses\" in the document, and then extract everything in the address for the borrower. We identified 4 possible patterns for this. \n",
    "\n",
    "## Date\n",
    "We extract the date from the file name. All file names follow the pattern YYY--MM--DD--numbers_and_text. It returns a datetime object with the date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_words=['borrower','lender','rate','guarantee','agreement','guarantor','amendment']\n",
    "max_line_first_page=35 #This was decided after trying some values\n",
    "\n",
    "#Returns: Project Name, line number where it was found.\n",
    "def get_project_name(lines,line_num,unwanted_words=unwanted_words,max_line_first_page=max_line_first_page):\n",
    "    found_start=False\n",
    "    line_max=min([max_line_first_page,len(lines)]) \n",
    "    while line_num <line_max:\n",
    "        l=lines[line_num]\n",
    "        if found_start:\n",
    "            #Look for a line of text in between two parenthesis\n",
    "            m=re.search('\\(\\s*([a-z]+[(),:;a-z\\s\\d]+)(project)?\\s*\\)',l.lower())\n",
    "            if m!=None and len(m.group(1))>12:\n",
    "                #Sometimes Parenthesis can be messy, so we extract the text on the outermost parenthesis\n",
    "                if len(re.findall('\\(',m.group(0)))>1:\n",
    "                    name=extract_parenthesis(m.group(0))\n",
    "                    if len(name)>0: #This must have at least one string if the parenthesis were balanced\n",
    "                        name=name[0]\n",
    "                    else: #if the parenthesis were not balanced, return everything before the second (\n",
    "                        m=re.search('(.*)\\(',m.group(1))\n",
    "                        name=m.group(1)\n",
    "                else:\n",
    "                    name=m.group(1)\n",
    "                if len(name)>12 and not(any(elem in name.split(' ') for elem in unwanted_words)) and not ('general conditions' in name):\n",
    "                    return name,line_num\n",
    "        else:\n",
    "            words=l.lower().split(' ')\n",
    "            if ('loan' in words) or ('agreement' in words):\n",
    "                #Once we found the sentence with loan or agreement in it, we start looking for the Project Name\n",
    "                found_start=True\n",
    "                line_num-=1\n",
    "        line_num+=1\n",
    "    #If couldnt find a Project Name following the format, returns None\n",
    "    return None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns: Project Description, line number where it was found.\n",
    "def get_project_description(lines, line_num):\n",
    "    line_max=len(lines)\n",
    "    while line_num <line_max-2:\n",
    "        l=lines[line_num]\n",
    "        words=l.split(' ')\n",
    "        if all([w in words for w in ['Project','Description']]):\n",
    "            description=' '.join([lines[line_num], lines[line_num+1],lines[line_num+2]])\n",
    "            if 'objective' in description.lower():\n",
    "                return description, line_num\n",
    "        line_num+=1\n",
    "    return None,line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns loan_amount, currency, number of line where it was found and the paragraph\n",
    "def get_loan_amount_currency(lines, line_num0):\n",
    "    #Extract dollar amount\n",
    "    #Extract the values using Regular Expressions\n",
    "    currency_characters=u\"[$¢£¤¥֏؋৲৳৻૱௹฿៛\\u20a0-\\u20bd\\ua838\\ufdfc\\ufe69\\uff04\\uffe0\\uffe1\\uffe5\\uffe6]|\"\n",
    "    currency_abbs=u'[\\s\\(]\\s?[a-z]{1,3}'\n",
    "    regexp_amount='(amount|value).*?('+currency_characters+currency_abbs+')([ \\d]{6,})'\n",
    "\n",
    "    line_num=line_num0\n",
    "    while line_num<len(lines)-3:\n",
    "        #Combine with the following three lines\n",
    "        combined_lines=' '.join([lines[line_num],lines[line_num+1],lines[line_num+2],lines[line_num+3]]) \n",
    "        combined_lines=combined_lines.lower()\n",
    "        #Find the line where it talks about the loan amount\n",
    "        if all(elem in combined_lines for elem in ['bank','agrees','borrower','amount']):  \n",
    "            #Eliminate commas\n",
    "            combined_lines=combined_lines.replace(',','')\n",
    "            #Search the regular expression\n",
    "            value=re.search(regexp_amount,combined_lines)\n",
    "            if value!=None:\n",
    "                amount=value.group(3)\n",
    "                amount=amount.replace(' ','')\n",
    "                amount=int(amount)\n",
    "                currency=value.group(2)\n",
    "                currency=currency.replace('(','')\n",
    "                currency=currency.strip()\n",
    "                #Make double sure that the amount makes sense. \n",
    "                if amount>100000:\n",
    "                    return amount,currency,line_num, combined_lines\n",
    "        line_num+=1\n",
    "    #If we couldnt find an amount, return None\n",
    "    return None,None,line_num0,None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE HOW THIS WORKS\n",
    "\n",
    "def get_loan_paragraph(lines,line_num0):\n",
    "    line_num=line_num0\n",
    "    while line_num<len(lines)-3:\n",
    "        #Combine with the following three lines\n",
    "        combined_lines=' '.join([lines[line_num],lines[line_num+1],lines[line_num+2],lines[line_num+3]]) \n",
    "        combined_lines=combined_lines.lower()\n",
    "        #Find the line where it talks about the loan amount\n",
    "        if all(elem in combined_lines for elem in ['bank','agrees','borrower','amount']):  \n",
    "            #Eliminate commas and periods \n",
    "            #(sometimes periods are used as thousands separator, and we dont need to worry about cents)\n",
    "            combined_lines=combined_lines.replace(',','')\n",
    "            combined_lines=combined_lines.replace('.','')\n",
    "            \n",
    "            #Search for money with a regular expression\n",
    "            value=re.search('[ \\d]{6,}',combined_lines)\n",
    "            if value!=None:\n",
    "                    return combined_lines,line_num\n",
    "        line_num+=1\n",
    "    return '',line_num0\n",
    "\n",
    "\n",
    "#Returns loan_amount, currency, number of line where it was found and the paragraph\n",
    "def get_loan_amount_currency(loan_paragraph):\n",
    "    #Extract dollar amount\n",
    "    #Extract the values using Regular Expressions\n",
    "    currency_characters=u\"[$¢£¤¥֏؋৲৳৻૱௹฿៛\\u20a0-\\u20bd\\ua838\\ufdfc\\ufe69\\uff04\\uffe0\\uffe1\\uffe5\\uffe6]|\"\n",
    "    currency_abbs=u'[\\s\\(]\\s?[a-z]{1,3}'\n",
    "    regexp_amount='(amount|value).*?('+currency_characters+currency_abbs+')([ \\d]{6,})'\n",
    "\n",
    "    value=re.search(regexp_amount,paragraph)\n",
    "    if value!=None:\n",
    "        amount=value.group(3)\n",
    "        amount=amount.replace(' ','')\n",
    "        amount=int(amount)\n",
    "        currency=value.group(2)\n",
    "        currency=currency.replace('(','')\n",
    "        currency=currency.strip()\n",
    "        #Make double sure that the amount makes sense. \n",
    "        if amount>100000:\n",
    "            return amount,currency\n",
    "\n",
    "    #If we couldnt find an amount, return None\n",
    "    return None,None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_code(lines,max_line_first_page=max_line_first_page):\n",
    "    max_line=min(max_line_first_page,len(lines))\n",
    "    line_num=0\n",
    "    while line_num<max_line:\n",
    "        l=lines[line_num].lower()\n",
    "        m=re.search('numbers? .*?([a-z]{2,3})[ ]?$',l)\n",
    "        if m!=None:\n",
    "            code=m.group(1)\n",
    "            code=code.upper()\n",
    "            return code,line_num\n",
    "        line_num+=1\n",
    "    return None,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#extra common stop_words\n",
    "stop_words=stop_words.union(['bank', 'state','agreement', 'loan', 'development','number', 'international', 'whereas', 'therefore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text, stop_words=stop_words):\n",
    "    words=text.lower().split(' ')\n",
    "    words=[w for w in words if not w in stop_words]\n",
    "    text=' '.join(words).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_possible_country_names(lines, stop_words=stop_words):\n",
    "    for ind, line in enumerate(lines):\n",
    "        start=0\n",
    "        if start==0 and 'between' in line.lower():\n",
    "            start=max(ind-2,0)\n",
    "        if 'article' in line.lower():\n",
    "            #Combine all lines between start and the line before the word \"article\"\n",
    "            text='\\n'.join(lines[start:ind-1])\n",
    "            #Find all short sentences of all caps, of 4 or more letters. \n",
    "            possible_countries=re.findall('[A-Z]{4,}[A-Z ]+',text)\n",
    "            \n",
    "            #Clean all possible countries\n",
    "            possible_countries=[clean(possible,stop_words) for possible in possible_countries]\n",
    "            possible_countries=[possible for possible in possible_countries if not possible=='' and len(possible)>3]  \n",
    "            return '\\n'.join(possible_countries)\n",
    "        #Otherwise return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacing_and_lower(docu):\n",
    "    docu = docu.replace('  ',' ')\n",
    "    docu = docu.replace('   ',' ')\n",
    "    docu = docu.lower()\n",
    "    return docu\n",
    "\n",
    "def read_address(docu, pin0= 'addresses', pin1 = 'start', pin2 = 'end'):\n",
    "    start = docu.find(pin0)\n",
    "    borrower = docu[start:].find(pin1)\n",
    "    colon = docu[start+borrower:].find(':')\n",
    "    bank = docu[start+borrower+colon:].find(pin2)\n",
    "    add = docu[start+borrower+colon+1:start+borrower+colon+bank]\n",
    "    if 'in witness' in add:\n",
    "        end2 = docu[start+borrower+colon+1:].find('in witness')\n",
    "        add = add[:end2]\n",
    "    return add\n",
    "\n",
    "def get_address(text):\n",
    "    text=spacing_and_lower(text)\n",
    "    address = read_address(text, pin0 = 'addresses', pin1 = 'for the borrower', pin2 = 'for the bank')\n",
    "    if len(address) < 8:\n",
    "        address = read_address(text, pin0 = 'addresses', pin1 = 'for the borrower', pin2 = 'international bank')\n",
    "    if len(address) < 8 or len(address) >500:\n",
    "        address = read_address(text, pin0 = 'addresses', pin1 = 'address is', pin2 = 'the bank')\n",
    "    if len(address) < 8:\n",
    "        address = read_address(text, pin0 = 'addresses', pin1 = 'the borrower', pin2 = 'the world bank')\n",
    "    if len(address) < 8:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following Function extracts the date from the file_name and returns it as a datetime.datetime object\n",
    "def get_date_file_name(file_name):\n",
    "    file_split=file_name.split('--')\n",
    "    date=datetime.datetime.strptime(' '.join(file_split[0].split('_')[0:3]),'%Y %B %d')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we create empty columns for all the attributes and we extract them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Texts_DF['Project_name']=None\n",
    "All_Texts_DF['Project_desc']=None\n",
    "All_Texts_DF['Date']=None\n",
    "All_Texts_DF['Currency']=''\n",
    "All_Texts_DF['Amount_loan']=None\n",
    "All_Texts_DF['Loan_paragraph']=None\n",
    "All_Texts_DF['Country_code_pdf']=None\n",
    "All_Texts_DF['Possible_country_name']=None\n",
    "All_Texts_DF['Address']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in All_Texts_DF.index:\n",
    "    text=All_Texts_DF['extracted_text'][i]\n",
    "    file_name=All_Texts_DF['filename'][i]\n",
    "    \n",
    "    All_Texts_DF['Date'][i]=get_date_file_name(file_name)\n",
    "    \n",
    "    lines=separate_lines(text)\n",
    "    All_Texts_DF['Country_code_pdf'][i],line_num=get_country_code(lines)\n",
    "    All_Texts_DF['Project_name'][i],line_num=get_project_name(lines,line_num)\n",
    "    \n",
    "    paragraph,line_num=get_loan_paragraph(lines,0)\n",
    "    All_Texts_DF['Loan_paragraph'][i]=paragraph\n",
    "    \n",
    "    amount,currency=get_loan_amount_currency(paragraph)\n",
    "    All_Texts_DF['Currency'][i]=currency\n",
    "    All_Texts_DF['Amount_loan'][i]=amount\n",
    "    \n",
    "    \n",
    "    description, _=get_project_description(lines,line_num)\n",
    "    All_Texts_DF['Project_desc'][i]=description\n",
    "    \n",
    "    All_Texts_DF['Possible_country_name'][i]=get_possible_country_names(lines)\n",
    "    \n",
    "    All_Texts_DF['Address'][i]=get_address(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Name  78\n",
      "No Currency  222\n",
      "No Amount  222\n",
      "No Country Code  111\n",
      "No Project Description  838\n",
      "No Address  118\n"
     ]
    }
   ],
   "source": [
    "#How many NONEs?\n",
    "print('No Name ',All_Texts_DF.Project_name.isnull().sum())\n",
    "print('No Currency ',All_Texts_DF.Currency.isnull().sum())\n",
    "print('No Amount ',All_Texts_DF.Amount_loan.isnull().sum())\n",
    "print('No Country Code ',All_Texts_DF.Country_code_pdf.isnull().sum())\n",
    "print('No Project Description ',All_Texts_DF.Project_desc.isnull().sum())\n",
    "print('No Address ',All_Texts_DF.Address.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'All_Texts_DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-105853df82a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAll_Texts_DF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAll_Texts_DF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddress\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mAll_Texts_DF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddress_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'All_Texts_DF' is not defined"
     ]
    }
   ],
   "source": [
    "All_Texts_DF[All_Texts_DF.Address==All_Texts_DF.Address_2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We couldnt extract all the info for:  428  PDFs.\n"
     ]
    }
   ],
   "source": [
    "#Dont Want to count empty description as a NONE PDF (maybe the title has enough information)\n",
    "All_Texts_DF.loc[All_Texts_DF.Project_desc.isnull(),'Project_desc']=''\n",
    "print('We couldnt extract all the info for: ',All_Texts_DF.shape[0]-All_Texts_DF.dropna().shape[0],' PDFs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export\n",
    "DF_to_export=All_Texts_DF.drop('extracted_text',axis=1)\n",
    "DF_to_export.to_csv('../data/Extracted_Attributes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Texts_DF.to_pickle('../../All_Texts.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
